{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-20T21:22:29.686993Z",
     "start_time": "2024-10-20T21:22:29.581240Z"
    }
   },
   "source": [
    "# To manipulate and analyze data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "# To visualize data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To used time-related functions\n",
    "import time\n",
    "\n",
    "# To parse JSON data\n",
    "import json\n",
    "\n",
    "# to load the natural language toolkit\n",
    "import nltk\n",
    "nltk.download('stopwords')    # loading the stopwords\n",
    "# nltk.download('punkt')    # loading the punkt module used in tokenization\n",
    "# nltk.download('omw-1.4')    # dependency for tokenization\n",
    "nltk.download('wordnet')   # loading the wordnet module that is used in stemming\n",
    "\n",
    "\n",
    "# To build, tune, and evaluate ML models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# To load/create word embeddings\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# To work with transformer models\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# To implement progress bar related functionalities\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# To ignore unnecessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/christophebuffard/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/christophebuffard/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:11:46.250609Z",
     "start_time": "2024-10-21T00:11:46.245180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stock_news = pd.read_csv(\"stock_news.csv\")\n",
    "df = stock_news.copy()"
   ],
   "id": "edd6ecfdc46a15f8",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:11:46.740728Z",
     "start_time": "2024-10-21T00:11:46.735255Z"
    }
   },
   "cell_type": "code",
   "source": "df['Date'] = pd.to_datetime(df['Date'])",
   "id": "be64399421012551",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:11:47.162704Z",
     "start_time": "2024-10-21T00:11:47.159656Z"
    }
   },
   "cell_type": "code",
   "source": "df['Avg_Price'] = (df['Open'] + df['Close'] + df['High'] + df['Low']) / 4\n",
   "id": "eb023a300d472d77",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:11:47.601637Z",
     "start_time": "2024-10-21T00:11:47.597031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "label = {\n",
    "    1: 'positive',\n",
    "    0: 'neutral',\n",
    "    -1: 'negative'\n",
    "}\n",
    "df['Label'] = df['Label'].map(label)"
   ],
   "id": "b0139efef3f3d333",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:11:48.835686Z",
     "start_time": "2024-10-21T00:11:48.832182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rev_label = {\n",
    "    'positive': 2,\n",
    "    'neutral': 1,\n",
    "    'negative': 0\n",
    "}\n",
    "df['Label'] = df['Label'].map(rev_label)"
   ],
   "id": "108ccdb1438d6c17",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:04.919222Z",
     "start_time": "2024-10-21T00:12:04.912356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "# to remove common stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Create a custom transformer for text preprocessing\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def remove_special_characters(self, text):\n",
    "        pattern = '[^A-Za-z0-9]+'\n",
    "        return re.sub(pattern, ' ', text)\n",
    "\n",
    "    def to_lowercase(self, text):\n",
    "        return text.lower()\n",
    "\n",
    "    def remove_extra_whitespaces(self, text):\n",
    "        return text.strip()\n",
    "\n",
    "    def remove_stopwords(self, text):\n",
    "        return ' '.join([word for word in text.split() if word not in self.stopwords])\n",
    "\n",
    "    def apply_stemming(self, text):\n",
    "        return ' '.join([self.stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = self.remove_special_characters(text)\n",
    "        text = self.to_lowercase(text)\n",
    "        text = self.remove_extra_whitespaces(text)\n",
    "        text = self.remove_stopwords(text)\n",
    "        return self.apply_stemming(text)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.apply(self.preprocess)\n",
    "\n",
    "# Create a pipeline with the custom transformer\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('text_preprocessing', FunctionTransformer(lambda x: TextPreprocessor().fit_transform(x), validate=False))\n",
    "])"
   ],
   "id": "2d9c36393315bb54",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:06.224997Z",
     "start_time": "2024-10-21T00:12:06.038269Z"
    }
   },
   "cell_type": "code",
   "source": "df['News_clean'] = pipeline.transform(df['News'])",
   "id": "6d59ed75970cf00f",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:06.617272Z",
     "start_time": "2024-10-21T00:12:06.608796Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "6a3c27cc1b101f0b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date                                               News       Open  \\\n",
       "0 2019-01-02   The tech sector experienced a significant dec...  41.740002   \n",
       "1 2019-01-02   Apple lowered its fiscal Q1 revenue guidance ...  41.740002   \n",
       "2 2019-01-02   Apple cut its fiscal first quarter revenue fo...  41.740002   \n",
       "3 2019-01-02   This news article reports that yields on long...  41.740002   \n",
       "4 2019-01-02   Apple's revenue warning led to a decline in U...  41.740002   \n",
       "\n",
       "        High        Low      Close     Volume  Label  Avg_Price  \\\n",
       "0  42.244999  41.482498  40.246914  130672400      0  41.428603   \n",
       "1  42.244999  41.482498  40.246914  130672400      0  41.428603   \n",
       "2  42.244999  41.482498  40.246914  130672400      0  41.428603   \n",
       "3  42.244999  41.482498  40.246914  130672400      0  41.428603   \n",
       "4  42.244999  41.482498  40.246914  130672400      0  41.428603   \n",
       "\n",
       "                                          News_clean  \n",
       "0  tech sector experienc signific declin aftermar...  \n",
       "1  appl lower fiscal q1 revenu guidanc 84 billion...  \n",
       "2  appl cut fiscal first quarter revenu forecast ...  \n",
       "3  news articl report yield long date u treasuri ...  \n",
       "4  appl revenu warn led declin usd jpi pair gain ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Label</th>\n",
       "      <th>Avg_Price</th>\n",
       "      <th>News_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>The tech sector experienced a significant dec...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>tech sector experienc signific declin aftermar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>Apple lowered its fiscal Q1 revenue guidance ...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>appl lower fiscal q1 revenu guidanc 84 billion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>Apple cut its fiscal first quarter revenue fo...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>appl cut fiscal first quarter revenu forecast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>This news article reports that yields on long...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>news articl report yield long date u treasuri ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>Apple's revenue warning led to a decline in U...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>appl revenu warn led declin usd jpi pair gain ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:08.388651Z",
     "start_time": "2024-10-21T00:12:08.384902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Date set starting date: {df['Date'].min()}\")\n",
    "start_date = df['Date'].min()\n",
    "print(f\"Datea set end date: {df['Date'].max()}\")\n",
    "print(f\"Duration: {df['Date'].max() - df['Date'].min()}\")"
   ],
   "id": "160a5e5a371ed6ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date set starting date: 2019-01-02 00:00:00\n",
      "Datea set end date: 2019-04-30 00:00:00\n",
      "Duration: 118 days 00:00:00\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:09.936600Z",
     "start_time": "2024-10-21T00:12:09.932367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_point = (df['Date'].max() - df['Date'].min())*0.7 # 60% of data\n",
    "print(f\"Train point: {train_point}\")\n",
    "test_val_split = (df['Date'].max() - df['Date'].min())*0.15 # 50% of the remaining %30\n",
    "print(f\"Test-Val Split: {test_val_split}\")"
   ],
   "id": "c7fadbf4c9f78d80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train point: 82 days 14:24:00\n",
      "Test-Val Split: 17 days 16:48:00\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:10.526378Z",
     "start_time": "2024-10-21T00:12:10.518090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = df[(df['Date'] < start_date + train_point)].reset_index()    #Complete the code to select all rows where the 'Date' is before '2019-04-01'\n",
    "X_val = df[(df['Date'] >= start_date + train_point) & (df['Date'] < start_date + train_point + test_val_split)].reset_index()    #Complete the code to select all rows where the 'Date' is from '2019-04-01 to '2019-04-16' (excluded)\n",
    "X_test = df[df['Date'] >= start_date + train_point + test_val_split].reset_index()    #Complete the code to select all rows where the 'Date' is from '2019-04-16' till the end."
   ],
   "id": "ec187e3cc7878ebf",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:11.033546Z",
     "start_time": "2024-10-21T00:12:11.029645Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape, X_val.shape, X_test.shape",
   "id": "daea89c634929ce9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((274, 11), (31, 11), (44, 11))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:11.609637Z",
     "start_time": "2024-10-21T00:12:11.605348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train.drop(columns=['index', 'Date'], inplace=True)\n",
    "X_val.drop(columns=['index', 'Date'], inplace=True)\n",
    "X_test.drop(columns=['index', 'Date'], inplace=True)"
   ],
   "id": "febe5e14f43a5e33",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:12.452906Z",
     "start_time": "2024-10-21T00:12:12.448802Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape, X_val.shape, X_test.shape",
   "id": "4551fc95bd218154",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((274, 9), (31, 9), (44, 9))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:13.011335Z",
     "start_time": "2024-10-21T00:12:13.008388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_train = X_train['Label']\n",
    "y_val = X_val['Label']\n",
    "y_test = X_test['Label']"
   ],
   "id": "b415b335a19b5e10",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:14.178679Z",
     "start_time": "2024-10-21T00:12:14.174307Z"
    }
   },
   "cell_type": "code",
   "source": "y_train.head(20)",
   "id": "232b8ad047dcf72",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     1\n",
       "6     2\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    1\n",
       "11    0\n",
       "12    0\n",
       "13    1\n",
       "14    0\n",
       "15    0\n",
       "16    2\n",
       "17    1\n",
       "18    0\n",
       "19    1\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:17.593625Z",
     "start_time": "2024-10-21T00:12:17.584173Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.head(20)",
   "id": "40bf29f875f65bfb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 News       Open       High  \\\n",
       "0    The tech sector experienced a significant dec...  41.740002  42.244999   \n",
       "1    Apple lowered its fiscal Q1 revenue guidance ...  41.740002  42.244999   \n",
       "2    Apple cut its fiscal first quarter revenue fo...  41.740002  42.244999   \n",
       "3    This news article reports that yields on long...  41.740002  42.244999   \n",
       "4    Apple's revenue warning led to a decline in U...  41.740002  42.244999   \n",
       "5   Apple CEO Tim Cook discussed the company's Q1 ...  41.740002  42.244999   \n",
       "6    Roku Inc has announced plans to offer premium...  41.740002  42.244999   \n",
       "7    Wall Street saw modest gains on Wednesday but...  41.740002  42.244999   \n",
       "8    Apple's fiscal first quarter revenue came in ...  41.740002  42.244999   \n",
       "9    Apple Inc. lowered its quarterly sales foreca...  41.740002  42.244999   \n",
       "10   The Australian dollar experienced significant...  41.740002  42.244999   \n",
       "11   In early Asian trading on Thursday, the Japan...  41.740002  42.244999   \n",
       "12   The dollar fell from above 109 to 106.67 afte...  41.740002  42.244999   \n",
       "13   RBC Capital maintains its bullish stance on A...  41.740002  42.244999   \n",
       "14   Oil prices dropped on Thursday as investor se...  43.570000  43.787498   \n",
       "15   In this news article, investors' concerns abo...  43.570000  43.787498   \n",
       "16   In Asia, gold prices rose to over six-month h...  43.570000  43.787498   \n",
       "17   Fears of a global economic slowdown led to a ...  43.570000  43.787498   \n",
       "18   In Thursday trading, long-term US Treasury yi...  43.570000  43.787498   \n",
       "19   Gold prices have reached their highest level ...  43.570000  43.787498   \n",
       "\n",
       "          Low      Close     Volume  Label  Avg_Price  \\\n",
       "0   41.482498  40.246914  130672400      0  41.428603   \n",
       "1   41.482498  40.246914  130672400      0  41.428603   \n",
       "2   41.482498  40.246914  130672400      0  41.428603   \n",
       "3   41.482498  40.246914  130672400      0  41.428603   \n",
       "4   41.482498  40.246914  130672400      0  41.428603   \n",
       "5   41.482498  40.246914  130672400      1  41.428603   \n",
       "6   41.482498  40.246914  130672400      2  41.428603   \n",
       "7   41.482498  40.246914  130672400      0  41.428603   \n",
       "8   41.482498  40.246914  130672400      0  41.428603   \n",
       "9   41.482498  40.246914  130672400      0  41.428603   \n",
       "10  41.482498  40.246914  130672400      1  41.428603   \n",
       "11  41.482498  40.246914  130672400      0  41.428603   \n",
       "12  41.482498  40.246914  130672400      0  41.428603   \n",
       "13  41.482498  40.246914  130672400      1  41.428603   \n",
       "14  43.222500  42.470604  103544800      0  43.262650   \n",
       "15  43.222500  42.470604  103544800      0  43.262650   \n",
       "16  43.222500  42.470604  103544800      2  43.262650   \n",
       "17  43.222500  42.470604  103544800      1  43.262650   \n",
       "18  43.222500  42.470604  103544800      0  43.262650   \n",
       "19  43.222500  42.470604  103544800      1  43.262650   \n",
       "\n",
       "                                           News_clean  \n",
       "0   tech sector experienc signific declin aftermar...  \n",
       "1   appl lower fiscal q1 revenu guidanc 84 billion...  \n",
       "2   appl cut fiscal first quarter revenu forecast ...  \n",
       "3   news articl report yield long date u treasuri ...  \n",
       "4   appl revenu warn led declin usd jpi pair gain ...  \n",
       "5   appl ceo tim cook discuss compani q1 warn cnbc...  \n",
       "6   roku inc announc plan offer premium video chan...  \n",
       "7   wall street saw modest gain wednesday threaten...  \n",
       "8   appl fiscal first quarter revenu came analyst ...  \n",
       "9   appl inc lower quarterli sale forecast fiscal ...  \n",
       "10  australian dollar experienc signific volatil t...  \n",
       "11  earli asian trade thursday japanes yen surg u ...  \n",
       "12  dollar fell 109 106 67 appl revenu warn 10 yea...  \n",
       "13  rbc capit maintain bullish stanc appl keep out...  \n",
       "14  oil price drop thursday investor sentiment rem...  \n",
       "15  news articl investor concern slow chines globa...  \n",
       "16  asia gold price rose six month high concern gl...  \n",
       "17  fear global econom slowdown led declin us doll...  \n",
       "18  thursday trade long term us treasuri yield dro...  \n",
       "19  gold price reach highest level sinc mid june y...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Label</th>\n",
       "      <th>Avg_Price</th>\n",
       "      <th>News_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The tech sector experienced a significant dec...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>tech sector experienc signific declin aftermar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple lowered its fiscal Q1 revenue guidance ...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>appl lower fiscal q1 revenu guidanc 84 billion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple cut its fiscal first quarter revenue fo...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>appl cut fiscal first quarter revenu forecast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This news article reports that yields on long...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>news articl report yield long date u treasuri ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple's revenue warning led to a decline in U...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>appl revenu warn led declin usd jpi pair gain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apple CEO Tim Cook discussed the company's Q1 ...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>1</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>appl ceo tim cook discuss compani q1 warn cnbc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Roku Inc has announced plans to offer premium...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>2</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>roku inc announc plan offer premium video chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wall Street saw modest gains on Wednesday but...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>wall street saw modest gain wednesday threaten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Apple's fiscal first quarter revenue came in ...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>appl fiscal first quarter revenu came analyst ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apple Inc. lowered its quarterly sales foreca...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>appl inc lower quarterli sale forecast fiscal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Australian dollar experienced significant...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>1</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>australian dollar experienc signific volatil t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>In early Asian trading on Thursday, the Japan...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>earli asian trade thursday japanes yen surg u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The dollar fell from above 109 to 106.67 afte...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>0</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>dollar fell 109 106 67 appl revenu warn 10 yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RBC Capital maintains its bullish stance on A...</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.244999</td>\n",
       "      <td>41.482498</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>130672400</td>\n",
       "      <td>1</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>rbc capit maintain bullish stanc appl keep out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oil prices dropped on Thursday as investor se...</td>\n",
       "      <td>43.570000</td>\n",
       "      <td>43.787498</td>\n",
       "      <td>43.222500</td>\n",
       "      <td>42.470604</td>\n",
       "      <td>103544800</td>\n",
       "      <td>0</td>\n",
       "      <td>43.262650</td>\n",
       "      <td>oil price drop thursday investor sentiment rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>In this news article, investors' concerns abo...</td>\n",
       "      <td>43.570000</td>\n",
       "      <td>43.787498</td>\n",
       "      <td>43.222500</td>\n",
       "      <td>42.470604</td>\n",
       "      <td>103544800</td>\n",
       "      <td>0</td>\n",
       "      <td>43.262650</td>\n",
       "      <td>news articl investor concern slow chines globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>In Asia, gold prices rose to over six-month h...</td>\n",
       "      <td>43.570000</td>\n",
       "      <td>43.787498</td>\n",
       "      <td>43.222500</td>\n",
       "      <td>42.470604</td>\n",
       "      <td>103544800</td>\n",
       "      <td>2</td>\n",
       "      <td>43.262650</td>\n",
       "      <td>asia gold price rose six month high concern gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fears of a global economic slowdown led to a ...</td>\n",
       "      <td>43.570000</td>\n",
       "      <td>43.787498</td>\n",
       "      <td>43.222500</td>\n",
       "      <td>42.470604</td>\n",
       "      <td>103544800</td>\n",
       "      <td>1</td>\n",
       "      <td>43.262650</td>\n",
       "      <td>fear global econom slowdown led declin us doll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>In Thursday trading, long-term US Treasury yi...</td>\n",
       "      <td>43.570000</td>\n",
       "      <td>43.787498</td>\n",
       "      <td>43.222500</td>\n",
       "      <td>42.470604</td>\n",
       "      <td>103544800</td>\n",
       "      <td>0</td>\n",
       "      <td>43.262650</td>\n",
       "      <td>thursday trade long term us treasuri yield dro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gold prices have reached their highest level ...</td>\n",
       "      <td>43.570000</td>\n",
       "      <td>43.787498</td>\n",
       "      <td>43.222500</td>\n",
       "      <td>42.470604</td>\n",
       "      <td>103544800</td>\n",
       "      <td>1</td>\n",
       "      <td>43.262650</td>\n",
       "      <td>gold price reach highest level sinc mid june y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:19.305445Z",
     "start_time": "2024-10-21T00:12:19.300981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating a list of all words in our data\n",
    "words_list = [item.split(\" \") for item in df['News_clean'].values]"
   ],
   "id": "343a246a5e19618f",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:20.009946Z",
     "start_time": "2024-10-21T00:12:19.851238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating an instance of Word2Vec\n",
    "vec_size = 300\n",
    "model_W2V = Word2Vec(words_list, vector_size = vec_size, min_count = 1, window=5, workers = 6)"
   ],
   "id": "ede45563c7aa6b2f",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:20.401088Z",
     "start_time": "2024-10-21T00:12:20.365269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieving the words present in the Word2Vec model's vocabulary\n",
    "words = list(model_W2V.wv.key_to_index.keys())\n",
    "\n",
    "# Retrieving word vectors for all the words present in the model's vocabulary\n",
    "wvs = model_W2V.wv[words].tolist()\n",
    "\n",
    "# Creating a dictionary of words and their corresponding vectors\n",
    "word_vector_dict = dict(zip(words, wvs))\n"
   ],
   "id": "a88c872a0d0dc8ae",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:21.384142Z",
     "start_time": "2024-10-21T00:12:21.379501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute the average\n",
    "def average_vectorizer_Word2Vec(doc, words, word_vector):\n",
    "    \"\"\"\n",
    "    Computes the average vector representation of a sentence using Word2Vec.\n",
    "    :param doc:\n",
    "    :param words: list of words in the model vocabulary\n",
    "    :param word_vector: dictionary of words and their corresponding vectors\n",
    "    :return: feature vector\n",
    "    \"\"\"\n",
    "    # Initializing a feature vector for the sentence\n",
    "    feature_vector = np.zeros((vec_size,), dtype=\"float64\")\n",
    "\n",
    "    # Creating a list of words in the sentence that are present in the model vocabulary\n",
    "    words_in_vocab = [word for word in doc.split() if word in words]\n",
    "\n",
    "    # adding the vector representations of the words\n",
    "    for word in words_in_vocab:\n",
    "        feature_vector += np.array(word_vector[word])\n",
    "\n",
    "    # Dividing by the number of words to get the average vector\n",
    "    if len(words_in_vocab) != 0:\n",
    "        feature_vector /= len(words_in_vocab)\n",
    "\n",
    "    return feature_vector"
   ],
   "id": "5815c1aa52f92642",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:22.015663Z",
     "start_time": "2024-10-21T00:12:22.012123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def vectorized_document(df, target, words, word_vector):\n",
    "    \"\"\"\n",
    "    Vectorized a document using Word2Vec.\n",
    "    :param df: the datafram to vectorize\n",
    "    :param target: the target column to vectorize\n",
    "    :param words: words in the model vocabulary\n",
    "    :param word_vector: vocabulary of words and their corresponding vectors\n",
    "    :return: a pd.Datafram\n",
    "    \"\"\"\n",
    "    tmp = pd.DataFrame(df[target].apply(lambda x: average_vectorizer_Word2Vec(x, words, word_vector).tolist()))\n",
    "    return pd.DataFrame(tmp[target].tolist(),columns=['Feature' + str(i) for i in range(vec_size)])\n"
   ],
   "id": "b3b3cb5cba7a8f4c",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:22.906964Z",
     "start_time": "2024-10-21T00:12:22.699012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_wv = vectorized_document(X_train, 'News_clean', words, word_vector_dict)\n",
    "X_train_wv[['Volume', 'Avg_Price']] = X_train[['Volume', 'Avg_Price']].astype(float)"
   ],
   "id": "3c3ec0f2a21bc957",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:23.309411Z",
     "start_time": "2024-10-21T00:12:23.277872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_val_wv = vectorized_document(X_val, 'News_clean', words, word_vector_dict)\n",
    "X_val_wv[['Volume', 'Avg_Price']] = X_val[['Volume', 'Avg_Price']].astype(float)"
   ],
   "id": "cf4ac6bbcbcdf3c0",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:12:23.837873Z",
     "start_time": "2024-10-21T00:12:23.793322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test_wv = vectorized_document(X_test, 'News_clean', words, word_vector_dict)\n",
    "X_test_wv[['Volume', 'Avg_Price']] = X_val[['Volume', 'Avg_Price']].astype(float)"
   ],
   "id": "d4699742e61fc82a",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:16:22.008265Z",
     "start_time": "2024-10-21T00:16:21.995521Z"
    }
   },
   "cell_type": "code",
   "source": "X_train_wv.head()",
   "id": "b1db854d1143ae7e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  Feature6  \\\n",
       "0  0.000216  0.004676 -0.000964  0.002499  0.000301 -0.006099  0.003429   \n",
       "1  0.000816  0.005574 -0.001678  0.003457 -0.000452 -0.007578  0.003915   \n",
       "2  0.000437  0.004267 -0.001060  0.002809 -0.000246 -0.006333  0.002605   \n",
       "3 -0.000498  0.005355 -0.001262  0.003202 -0.000261 -0.006521  0.003137   \n",
       "4  0.000690  0.003390 -0.000706  0.002732 -0.000233 -0.005372  0.002772   \n",
       "\n",
       "   Feature7  Feature8  Feature9  ...  Feature292  Feature293  Feature294  \\\n",
       "0  0.009592  0.002219 -0.001178  ...    0.005197    0.000752    0.005170   \n",
       "1  0.011049  0.002374 -0.000585  ...    0.005898    0.000718    0.005173   \n",
       "2  0.009335  0.002152 -0.000636  ...    0.005287    0.000401    0.004533   \n",
       "3  0.009843  0.002009 -0.001162  ...    0.004688    0.000438    0.004628   \n",
       "4  0.007674  0.001986 -0.000168  ...    0.004659    0.000782    0.004412   \n",
       "\n",
       "   Feature295  Feature296  Feature297  Feature298  Feature299       Volume  \\\n",
       "0    0.006167    0.000384   -0.002627    0.003587   -0.000261  130672400.0   \n",
       "1    0.006782    0.001071   -0.003221    0.004376   -0.000098  130672400.0   \n",
       "2    0.005981    0.000992   -0.003503    0.003969   -0.000123  130672400.0   \n",
       "3    0.005598    0.000988   -0.002630    0.003194    0.000119  130672400.0   \n",
       "4    0.004935    0.000705   -0.002466    0.003496   -0.000119  130672400.0   \n",
       "\n",
       "   Avg_Price  \n",
       "0  41.428603  \n",
       "1  41.428603  \n",
       "2  41.428603  \n",
       "3  41.428603  \n",
       "4  41.428603  \n",
       "\n",
       "[5 rows x 302 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature0</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>Feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature292</th>\n",
       "      <th>Feature293</th>\n",
       "      <th>Feature294</th>\n",
       "      <th>Feature295</th>\n",
       "      <th>Feature296</th>\n",
       "      <th>Feature297</th>\n",
       "      <th>Feature298</th>\n",
       "      <th>Feature299</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Avg_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>-0.006099</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>-0.001178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>-0.002627</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>130672400.0</td>\n",
       "      <td>41.428603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>-0.001678</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>-0.000452</td>\n",
       "      <td>-0.007578</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>-0.000585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>-0.003221</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>130672400.0</td>\n",
       "      <td>41.428603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>-0.001060</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>-0.006333</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>-0.000636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>-0.003503</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>130672400.0</td>\n",
       "      <td>41.428603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000498</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>-0.001262</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>-0.006521</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>-0.001162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>-0.002630</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>130672400.0</td>\n",
       "      <td>41.428603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.005372</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>-0.002466</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>130672400.0</td>\n",
       "      <td>41.428603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 302 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### GloVe\n",
   "id": "b3428155db0c9a17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:13:11.841529Z",
     "start_time": "2024-10-21T00:12:25.900982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Converting the Stanford GloVe model vector format to word2vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_input_file = 'glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# load the Stanford GloVe model\n",
    "filename = 'glove.6B.100d.txt.word2vec'\n",
    "glove_model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "# Checking the size of the vocabulary\n",
    "print(\"Length of the vocabulary is\", len(glove_model.index_to_key))"
   ],
   "id": "c1211dc3caba8646",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the vocabulary is 400000\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:13:11.913704Z",
     "start_time": "2024-10-21T00:13:11.908865Z"
    }
   },
   "cell_type": "code",
   "source": "glove_words = glove_model.index_to_key",
   "id": "df82f61e726f31ec",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:13:12.320757Z",
     "start_time": "2024-10-21T00:13:12.221138Z"
    }
   },
   "cell_type": "code",
   "source": "glove_word_vector_dict = dict(zip(glove_model.index_to_key,list(glove_model.vectors)))",
   "id": "db7c44202e1d9945",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:13:21.539551Z",
     "start_time": "2024-10-21T00:13:21.536022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute average\n",
    "def average_vectorizer_GloVe(doc):\n",
    "    \"\"\"\n",
    "    Computes the average vector representation of a sentence using GloVe.\n",
    "    :param doc:\n",
    "    :return: vector\n",
    "    \"\"\"\n",
    "    # Initializing a feature vector for the sentence\n",
    "    feature_vector = np.zeros((vec_size,), dtype=\"float64\")\n",
    "\n",
    "    # Creating a list of words in the sentence that are present in the model vocabulary\n",
    "    words_in_vocab = [word for word in doc.split() if word in glove_words]\n",
    "\n",
    "    # adding the vector representations of the words\n",
    "    for word in words_in_vocab:\n",
    "        feature_vector += np.array(glove_word_vector_dict[word])\n",
    "\n",
    "    # Dividing by the number of words to get the average vector\n",
    "    if len(words_in_vocab) != 0:\n",
    "        feature_vector /= len(words_in_vocab)\n",
    "\n",
    "    return feature_vector"
   ],
   "id": "ae1522e96858683f",
   "outputs": [],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:13:22.744741Z",
     "start_time": "2024-10-21T00:13:22.742466Z"
    }
   },
   "cell_type": "code",
   "source": "vec_size=100",
   "id": "95b16bf55c736a36",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:13:35.665680Z",
     "start_time": "2024-10-21T00:13:23.912953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_gl = vectorized_document(X_train, 'News_clean', glove_words, glove_word_vector_dict)\n",
    "X_train_gl[['Volume', 'Avg_Price']] = X_train[['Volume', 'Avg_Price']].astype(float)"
   ],
   "id": "e645e200cbf41ad0",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:13:41.252284Z",
     "start_time": "2024-10-21T00:13:39.710670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_val_gl = vectorized_document(X_val, 'News_clean', glove_words, glove_word_vector_dict)\n",
    "X_val_gl[['Volume', 'Avg_Price']] = X_train[['Volume', 'Avg_Price']].astype(float)"
   ],
   "id": "9a68e672f4c118e4",
   "outputs": [],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:13:45.255935Z",
     "start_time": "2024-10-21T00:13:42.833610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test_gl = vectorized_document(X_test, 'News_clean', glove_words, glove_word_vector_dict)\n",
    "X_test_gl[['Volume', 'Avg_Price']] = X_train[['Volume', 'Avg_Price']].astype(float)"
   ],
   "id": "ff3f6ef769c1e071",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:13:46.991178Z",
     "start_time": "2024-10-21T00:13:46.978529Z"
    }
   },
   "cell_type": "code",
   "source": "X_train_gl.head()",
   "id": "8d3a90747c722137",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  Feature6  \\\n",
       "0  0.021671  0.096785 -0.047464 -0.066726 -0.215078 -0.603108 -0.089054   \n",
       "1  0.171825  0.341351  0.234650 -0.042054 -0.082840 -0.600302 -0.060674   \n",
       "2  0.010512  0.270341  0.301482 -0.087113  0.075485 -0.476547 -0.039534   \n",
       "3 -0.147407  0.226970  0.377158  0.184659 -0.110523 -0.447424 -0.103314   \n",
       "4  0.040798  0.198312  0.071460  0.037332 -0.098294 -0.407203 -0.078844   \n",
       "\n",
       "   Feature7  Feature8  Feature9  ...  Feature92  Feature93  Feature94  \\\n",
       "0 -0.001979  0.114239 -0.132121  ...  -0.146394  -0.217284  -0.137730   \n",
       "1 -0.101788 -0.159387  0.023604  ...  -0.190244  -0.136070  -0.442046   \n",
       "2 -0.014161 -0.123561 -0.054536  ...  -0.095302  -0.220799  -0.559601   \n",
       "3  0.033698 -0.021951 -0.041905  ...  -0.276519   0.034750  -0.347012   \n",
       "4 -0.102327 -0.132380 -0.031861  ...  -0.051261  -0.364269  -0.216124   \n",
       "\n",
       "   Feature95  Feature96  Feature97  Feature98  Feature99       Volume  \\\n",
       "0   0.162514   0.208869   0.056668   0.186156  -0.025540  130672400.0   \n",
       "1   0.225178   0.175980  -0.036701   0.410090  -0.159631  130672400.0   \n",
       "2   0.130351   0.039756  -0.088995   0.484577  -0.204774  130672400.0   \n",
       "3   0.131816   0.201519  -0.220721   0.328415  -0.101222  130672400.0   \n",
       "4   0.242409   0.243280  -0.071136   0.173813  -0.131392  130672400.0   \n",
       "\n",
       "   Avg_Price  \n",
       "0  41.428603  \n",
       "1  41.428603  \n",
       "2  41.428603  \n",
       "3  41.428603  \n",
       "4  41.428603  \n",
       "\n",
       "[5 rows x 102 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature0</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>Feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature92</th>\n",
       "      <th>Feature93</th>\n",
       "      <th>Feature94</th>\n",
       "      <th>Feature95</th>\n",
       "      <th>Feature96</th>\n",
       "      <th>Feature97</th>\n",
       "      <th>Feature98</th>\n",
       "      <th>Feature99</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Avg_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021671</td>\n",
       "      <td>0.096785</td>\n",
       "      <td>-0.047464</td>\n",
       "      <td>-0.066726</td>\n",
       "      <td>-0.215078</td>\n",
       "      <td>-0.603108</td>\n",
       "      <td>-0.089054</td>\n",
       "      <td>-0.001979</td>\n",
       "      <td>0.114239</td>\n",
       "      <td>-0.132121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146394</td>\n",
       "      <td>-0.217284</td>\n",
       "      <td>-0.137730</td>\n",
       "      <td>0.162514</td>\n",
       "      <td>0.208869</td>\n",
       "      <td>0.056668</td>\n",
       "      <td>0.186156</td>\n",
       "      <td>-0.025540</td>\n",
       "      <td>130672400.0</td>\n",
       "      <td>41.428603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171825</td>\n",
       "      <td>0.341351</td>\n",
       "      <td>0.234650</td>\n",
       "      <td>-0.042054</td>\n",
       "      <td>-0.082840</td>\n",
       "      <td>-0.600302</td>\n",
       "      <td>-0.060674</td>\n",
       "      <td>-0.101788</td>\n",
       "      <td>-0.159387</td>\n",
       "      <td>0.023604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190244</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>-0.442046</td>\n",
       "      <td>0.225178</td>\n",
       "      <td>0.175980</td>\n",
       "      <td>-0.036701</td>\n",
       "      <td>0.410090</td>\n",
       "      <td>-0.159631</td>\n",
       "      <td>130672400.0</td>\n",
       "      <td>41.428603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010512</td>\n",
       "      <td>0.270341</td>\n",
       "      <td>0.301482</td>\n",
       "      <td>-0.087113</td>\n",
       "      <td>0.075485</td>\n",
       "      <td>-0.476547</td>\n",
       "      <td>-0.039534</td>\n",
       "      <td>-0.014161</td>\n",
       "      <td>-0.123561</td>\n",
       "      <td>-0.054536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095302</td>\n",
       "      <td>-0.220799</td>\n",
       "      <td>-0.559601</td>\n",
       "      <td>0.130351</td>\n",
       "      <td>0.039756</td>\n",
       "      <td>-0.088995</td>\n",
       "      <td>0.484577</td>\n",
       "      <td>-0.204774</td>\n",
       "      <td>130672400.0</td>\n",
       "      <td>41.428603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.147407</td>\n",
       "      <td>0.226970</td>\n",
       "      <td>0.377158</td>\n",
       "      <td>0.184659</td>\n",
       "      <td>-0.110523</td>\n",
       "      <td>-0.447424</td>\n",
       "      <td>-0.103314</td>\n",
       "      <td>0.033698</td>\n",
       "      <td>-0.021951</td>\n",
       "      <td>-0.041905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276519</td>\n",
       "      <td>0.034750</td>\n",
       "      <td>-0.347012</td>\n",
       "      <td>0.131816</td>\n",
       "      <td>0.201519</td>\n",
       "      <td>-0.220721</td>\n",
       "      <td>0.328415</td>\n",
       "      <td>-0.101222</td>\n",
       "      <td>130672400.0</td>\n",
       "      <td>41.428603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040798</td>\n",
       "      <td>0.198312</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.037332</td>\n",
       "      <td>-0.098294</td>\n",
       "      <td>-0.407203</td>\n",
       "      <td>-0.078844</td>\n",
       "      <td>-0.102327</td>\n",
       "      <td>-0.132380</td>\n",
       "      <td>-0.031861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051261</td>\n",
       "      <td>-0.364269</td>\n",
       "      <td>-0.216124</td>\n",
       "      <td>0.242409</td>\n",
       "      <td>0.243280</td>\n",
       "      <td>-0.071136</td>\n",
       "      <td>0.173813</td>\n",
       "      <td>-0.131392</td>\n",
       "      <td>130672400.0</td>\n",
       "      <td>41.428603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sentence transformer",
   "id": "8eb86bedb21b7937"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:14:09.090813Z",
     "start_time": "2024-10-21T00:14:09.087584Z"
    }
   },
   "cell_type": "code",
   "source": "from sentence_transformers import SentenceTransformer",
   "id": "7490cb1ffb8b2e9e",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:14:20.318340Z",
     "start_time": "2024-10-21T00:14:10.172056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Defining the model\n",
    "model_st = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ],
   "id": "57785147618e7206",
   "outputs": [],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:14:41.120809Z",
     "start_time": "2024-10-21T00:14:41.118205Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "e44cd56c5a892c42",
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:14:43.793973Z",
     "start_time": "2024-10-21T00:14:43.791519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setting the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "d235a7c3bb690cc5",
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:15:49.031041Z",
     "start_time": "2024-10-21T00:15:46.314025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encoding the dataset\n",
    "X_train_st = model_st.encode(X_train['News'], show_progress_bar=True, device=device)\n",
    "X_val_st = model_st.encode(X_val['News'], show_progress_bar=True, device=device)\n",
    "X_test_st = model_st.encode(X_test['News'], show_progress_bar=True, device=device)"
   ],
   "id": "9c30642739f3ca75",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 9/9 [00:02<00:00,  4.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  5.65it/s]\n"
     ]
    }
   ],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:15:50.497629Z",
     "start_time": "2024-10-21T00:15:50.495150Z"
    }
   },
   "cell_type": "code",
   "source": "size = X_train_st.shape[1]",
   "id": "db4d1b3afc7ff553",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:15:51.352472Z",
     "start_time": "2024-10-21T00:15:51.342042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_st = pd.DataFrame(X_train_st)\n",
    "X_train_st.columns = ['Feature' + str(i) for i in range(size)]\n",
    "X_train_st[['Avg_Price', 'Volume']] = X_train[['Avg_Price', 'Volume']].astype(float)\n",
    "\n",
    "X_val_st = pd.DataFrame(X_val_st)\n",
    "X_val_st.columns = ['Feature' + str(i) for i in range(size)]\n",
    "X_val_st[['Avg_Price', 'Volume']] = X_val[['Avg_Price', 'Volume']].astype(float)\n",
    "\n",
    "X_test_st = pd.DataFrame(X_test_st)\n",
    "X_test_st.columns = ['Feature' + str(i) for i in range(size)]\n",
    "X_test_st[['Avg_Price', 'Volume']] = X_test[['Avg_Price', 'Volume']].astype(float)"
   ],
   "id": "52b48710c704a47e",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:15:53.310553Z",
     "start_time": "2024-10-21T00:15:53.298807Z"
    }
   },
   "cell_type": "code",
   "source": "X_train_st.head()",
   "id": "afc19e78ef7a5ece",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  Feature6  \\\n",
       "0 -0.002023 -0.036774  0.077354  0.046713  0.032552  0.002102  0.043283   \n",
       "1  0.013749  0.048934  0.089868  0.047753 -0.016835  0.044599  0.058056   \n",
       "2  0.030976  0.002636  0.090139  0.065713  0.003364 -0.001101  0.054763   \n",
       "3 -0.005294 -0.009259 -0.009670  0.057635 -0.025521 -0.037319 -0.060817   \n",
       "4 -0.002146  0.016797 -0.004066  0.082010  0.000499  0.013296  0.095996   \n",
       "\n",
       "   Feature7  Feature8  Feature9  ...  Feature376  Feature377  Feature378  \\\n",
       "0  0.039535  0.058228  0.008875  ...    0.003257   -0.000594   -0.055096   \n",
       "1  0.064367  0.060613  0.045722  ...   -0.002635   -0.020136   -0.077832   \n",
       "2  0.017497  0.027577  0.037116  ...   -0.028524   -0.053376   -0.107999   \n",
       "3  0.088207 -0.001648  0.016527  ...   -0.047937    0.001252   -0.067532   \n",
       "4  0.113363  0.051394 -0.006462  ...   -0.043031   -0.021357   -0.055635   \n",
       "\n",
       "   Feature379  Feature380  Feature381  Feature382  Feature383  Avg_Price  \\\n",
       "0   -0.027134   -0.003575   -0.131502    0.074163    0.057510  41.428603   \n",
       "1   -0.023604    0.053693   -0.123782    0.061468    0.003924  41.428603   \n",
       "2   -0.035857    0.007203   -0.111301    0.011414    0.078812  41.428603   \n",
       "3   -0.055194    0.034575   -0.112039    0.041667    0.098242  41.428603   \n",
       "4    0.054795    0.052306   -0.154250    0.005198    0.008437  41.428603   \n",
       "\n",
       "        Volume  \n",
       "0  130672400.0  \n",
       "1  130672400.0  \n",
       "2  130672400.0  \n",
       "3  130672400.0  \n",
       "4  130672400.0  \n",
       "\n",
       "[5 rows x 386 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature0</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>Feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature376</th>\n",
       "      <th>Feature377</th>\n",
       "      <th>Feature378</th>\n",
       "      <th>Feature379</th>\n",
       "      <th>Feature380</th>\n",
       "      <th>Feature381</th>\n",
       "      <th>Feature382</th>\n",
       "      <th>Feature383</th>\n",
       "      <th>Avg_Price</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002023</td>\n",
       "      <td>-0.036774</td>\n",
       "      <td>0.077354</td>\n",
       "      <td>0.046713</td>\n",
       "      <td>0.032552</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.043283</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>0.058228</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>-0.055096</td>\n",
       "      <td>-0.027134</td>\n",
       "      <td>-0.003575</td>\n",
       "      <td>-0.131502</td>\n",
       "      <td>0.074163</td>\n",
       "      <td>0.057510</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>130672400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.048934</td>\n",
       "      <td>0.089868</td>\n",
       "      <td>0.047753</td>\n",
       "      <td>-0.016835</td>\n",
       "      <td>0.044599</td>\n",
       "      <td>0.058056</td>\n",
       "      <td>0.064367</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>0.045722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002635</td>\n",
       "      <td>-0.020136</td>\n",
       "      <td>-0.077832</td>\n",
       "      <td>-0.023604</td>\n",
       "      <td>0.053693</td>\n",
       "      <td>-0.123782</td>\n",
       "      <td>0.061468</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>130672400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030976</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.090139</td>\n",
       "      <td>0.065713</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>0.054763</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.037116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028524</td>\n",
       "      <td>-0.053376</td>\n",
       "      <td>-0.107999</td>\n",
       "      <td>-0.035857</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>-0.111301</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>0.078812</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>130672400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.005294</td>\n",
       "      <td>-0.009259</td>\n",
       "      <td>-0.009670</td>\n",
       "      <td>0.057635</td>\n",
       "      <td>-0.025521</td>\n",
       "      <td>-0.037319</td>\n",
       "      <td>-0.060817</td>\n",
       "      <td>0.088207</td>\n",
       "      <td>-0.001648</td>\n",
       "      <td>0.016527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047937</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>-0.067532</td>\n",
       "      <td>-0.055194</td>\n",
       "      <td>0.034575</td>\n",
       "      <td>-0.112039</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.098242</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>130672400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002146</td>\n",
       "      <td>0.016797</td>\n",
       "      <td>-0.004066</td>\n",
       "      <td>0.082010</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.013296</td>\n",
       "      <td>0.095996</td>\n",
       "      <td>0.113363</td>\n",
       "      <td>0.051394</td>\n",
       "      <td>-0.006462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043031</td>\n",
       "      <td>-0.021357</td>\n",
       "      <td>-0.055635</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.052306</td>\n",
       "      <td>-0.154250</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.008437</td>\n",
       "      <td>41.428603</td>\n",
       "      <td>130672400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 386 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:15:55.947187Z",
     "start_time": "2024-10-21T00:15:55.934929Z"
    }
   },
   "cell_type": "code",
   "source": "X_val_st.head()",
   "id": "b734a25f288bf6e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  Feature6  \\\n",
       "0  0.000158 -0.029377  0.027311  0.009435  0.005225  0.013579 -0.035999   \n",
       "1 -0.045317 -0.045913  0.111688  0.099022  0.053137  0.001026  0.019429   \n",
       "2 -0.022719 -0.031737  0.002823  0.034345 -0.044363  0.025113 -0.005354   \n",
       "3 -0.119170  0.008578 -0.011554 -0.010010 -0.008426  0.058581  0.052131   \n",
       "4  0.039347 -0.093859  0.048436  0.042893  0.045026 -0.001638 -0.006283   \n",
       "\n",
       "   Feature7  Feature8  Feature9  ...  Feature376  Feature377  Feature378  \\\n",
       "0  0.061863  0.049671  0.009670  ...   -0.086341    0.028364   -0.049615   \n",
       "1  0.022210 -0.019778 -0.026104  ...   -0.045251    0.041996   -0.044994   \n",
       "2  0.007245  0.047596 -0.107752  ...   -0.044412   -0.037354    0.031592   \n",
       "3 -0.017450 -0.006025  0.063895  ...    0.049777   -0.077668   -0.022233   \n",
       "4  0.077525  0.013749  0.004450  ...   -0.071864    0.021245   -0.043629   \n",
       "\n",
       "   Feature379  Feature380  Feature381  Feature382  Feature383  Avg_Price  \\\n",
       "0   -0.039821    0.046718   -0.117746    0.015545    0.069136  46.904922   \n",
       "1   -0.061237    0.072046   -0.127659   -0.022423    0.131794  46.904922   \n",
       "2   -0.081242    0.105062   -0.080331    0.048208   -0.031003  46.904922   \n",
       "3   -0.021424    0.015831   -0.123832    0.051015    0.126861  46.904922   \n",
       "4   -0.015793   -0.018176   -0.069422    0.044052    0.065704  46.753120   \n",
       "\n",
       "        Volume  \n",
       "0  199202000.0  \n",
       "1  199202000.0  \n",
       "2  199202000.0  \n",
       "3  199202000.0  \n",
       "4  119393600.0  \n",
       "\n",
       "[5 rows x 386 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature0</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>Feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature376</th>\n",
       "      <th>Feature377</th>\n",
       "      <th>Feature378</th>\n",
       "      <th>Feature379</th>\n",
       "      <th>Feature380</th>\n",
       "      <th>Feature381</th>\n",
       "      <th>Feature382</th>\n",
       "      <th>Feature383</th>\n",
       "      <th>Avg_Price</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.029377</td>\n",
       "      <td>0.027311</td>\n",
       "      <td>0.009435</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.013579</td>\n",
       "      <td>-0.035999</td>\n",
       "      <td>0.061863</td>\n",
       "      <td>0.049671</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086341</td>\n",
       "      <td>0.028364</td>\n",
       "      <td>-0.049615</td>\n",
       "      <td>-0.039821</td>\n",
       "      <td>0.046718</td>\n",
       "      <td>-0.117746</td>\n",
       "      <td>0.015545</td>\n",
       "      <td>0.069136</td>\n",
       "      <td>46.904922</td>\n",
       "      <td>199202000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.045317</td>\n",
       "      <td>-0.045913</td>\n",
       "      <td>0.111688</td>\n",
       "      <td>0.099022</td>\n",
       "      <td>0.053137</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.019429</td>\n",
       "      <td>0.022210</td>\n",
       "      <td>-0.019778</td>\n",
       "      <td>-0.026104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045251</td>\n",
       "      <td>0.041996</td>\n",
       "      <td>-0.044994</td>\n",
       "      <td>-0.061237</td>\n",
       "      <td>0.072046</td>\n",
       "      <td>-0.127659</td>\n",
       "      <td>-0.022423</td>\n",
       "      <td>0.131794</td>\n",
       "      <td>46.904922</td>\n",
       "      <td>199202000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.022719</td>\n",
       "      <td>-0.031737</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.034345</td>\n",
       "      <td>-0.044363</td>\n",
       "      <td>0.025113</td>\n",
       "      <td>-0.005354</td>\n",
       "      <td>0.007245</td>\n",
       "      <td>0.047596</td>\n",
       "      <td>-0.107752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044412</td>\n",
       "      <td>-0.037354</td>\n",
       "      <td>0.031592</td>\n",
       "      <td>-0.081242</td>\n",
       "      <td>0.105062</td>\n",
       "      <td>-0.080331</td>\n",
       "      <td>0.048208</td>\n",
       "      <td>-0.031003</td>\n",
       "      <td>46.904922</td>\n",
       "      <td>199202000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.119170</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>-0.011554</td>\n",
       "      <td>-0.010010</td>\n",
       "      <td>-0.008426</td>\n",
       "      <td>0.058581</td>\n",
       "      <td>0.052131</td>\n",
       "      <td>-0.017450</td>\n",
       "      <td>-0.006025</td>\n",
       "      <td>0.063895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>-0.077668</td>\n",
       "      <td>-0.022233</td>\n",
       "      <td>-0.021424</td>\n",
       "      <td>0.015831</td>\n",
       "      <td>-0.123832</td>\n",
       "      <td>0.051015</td>\n",
       "      <td>0.126861</td>\n",
       "      <td>46.904922</td>\n",
       "      <td>199202000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039347</td>\n",
       "      <td>-0.093859</td>\n",
       "      <td>0.048436</td>\n",
       "      <td>0.042893</td>\n",
       "      <td>0.045026</td>\n",
       "      <td>-0.001638</td>\n",
       "      <td>-0.006283</td>\n",
       "      <td>0.077525</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071864</td>\n",
       "      <td>0.021245</td>\n",
       "      <td>-0.043629</td>\n",
       "      <td>-0.015793</td>\n",
       "      <td>-0.018176</td>\n",
       "      <td>-0.069422</td>\n",
       "      <td>0.044052</td>\n",
       "      <td>0.065704</td>\n",
       "      <td>46.753120</td>\n",
       "      <td>119393600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 386 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 157
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "67b37a1c0c7caff5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sentiment Analysis",
   "id": "c8b7fd20d08fcde2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:18:52.827845Z",
     "start_time": "2024-10-21T00:18:52.823810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'classifier': [\n",
    "        RandomForestClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss')  # XGBoost specific params\n",
    "    ],\n",
    "    # For tree-based classifiers\n",
    "    'classifier__n_estimators': [50, 100, 200],  # Hyperparameter for ensemble classifiers\n",
    "    'classifier__max_depth': [None, 10, 20, 30],  # Max depth for tree-based models\n",
    "    # For boosting models\n",
    "    'classifier__learning_rate': np.logspace(-3, 0, 4),  # Learning rate for boosting algorithms\n",
    "}"
   ],
   "id": "712985e8738bfb1a",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:20:20.823506Z",
     "start_time": "2024-10-21T00:20:20.818368Z"
    }
   },
   "cell_type": "code",
   "source": "param_grid",
   "id": "b888d9f97e34b7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': [RandomForestClassifier(),\n",
       "  AdaBoostClassifier(),\n",
       "  BaggingClassifier(),\n",
       "  GradientBoostingClassifier(),\n",
       "  DecisionTreeClassifier(),\n",
       "  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric='logloss',\n",
       "                feature_types=None, gamma=None, grow_policy=None,\n",
       "                importance_type=None, interaction_constraints=None,\n",
       "                learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "                max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "                n_jobs=None, num_parallel_tree=None, random_state=None, ...)],\n",
       " 'classifier__n_estimators': [100, 200, 300],\n",
       " 'classifier__max_depth': [3, 5, 10],\n",
       " 'classifier__min_samples_split': [2, 5, 10],\n",
       " 'classifier__min_samples_leaf': [1, 2, 4],\n",
       " 'classifier__bootstrap': [True, False],\n",
       " 'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
       " 'classifier__algorithm': ['SAMME', 'SAMME.R'],\n",
       " 'classifier__max_samples': [0.6, 0.8, 1.0],\n",
       " 'classifier__max_features': [0.6, 0.8, 1.0],\n",
       " 'classifier__bootstrap_features': [True, False],\n",
       " 'classifier__subsample': [0.6, 0.8, 1.0],\n",
       " 'classifier__criterion': ['gini', 'entropy'],\n",
       " 'classifier__splitter': ['best', 'random'],\n",
       " 'classifier__min_child_weight': [1, 3, 5],\n",
       " 'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
       " 'classifier__gamma': [0, 0.1, 0.2],\n",
       " 'classifier__scale_pos_weight': [1, 10, 25]}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:20:17.838660Z",
     "start_time": "2024-10-21T00:20:17.831645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'classifier': [\n",
    "        RandomForestClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    ],\n",
    "    # Hyperparameters for RandomForestClassifier\n",
    "    'classifier__n_estimators': [100, 200, 500],  # Number of trees in the forest\n",
    "    'classifier__max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'classifier__min_samples_split': [2, 5, 10],  # Minimum samples required to split an internal node\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],  # Minimum number of samples at a leaf node\n",
    "    'classifier__bootstrap': [True, False],  # Whether bootstrap samples are used\n",
    "\n",
    "    # Hyperparameters for AdaBoostClassifier\n",
    "    'classifier__n_estimators': [50, 100, 200],  # Number of boosting rounds\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.5, 1.0],  # Learning rate shrinks the contribution of each classifier\n",
    "    'classifier__algorithm': ['SAMME', 'SAMME.R'],  # Boosting algorithm\n",
    "\n",
    "    # Hyperparameters for BaggingClassifier\n",
    "    'classifier__n_estimators': [50, 100, 300],  # Number of base estimators in the ensemble\n",
    "    'classifier__max_samples': [0.6, 0.8, 1.0],  # Max number of samples to draw from X to train each base estimator\n",
    "    'classifier__max_features': [0.6, 0.8, 1.0],  # Max features to draw from X to train each base estimator\n",
    "    'classifier__bootstrap': [True, False],  # Whether bootstrap samples are used\n",
    "    'classifier__bootstrap_features': [True, False],  # Whether bootstrap samples are used when selecting features\n",
    "\n",
    "    # Hyperparameters for GradientBoostingClassifier\n",
    "    'classifier__n_estimators': [100, 200, 300],  # Number of boosting stages to be run\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],  # Shrinks contribution of each tree\n",
    "    'classifier__max_depth': [3, 5, 10],  # Maximum depth of the individual regression estimators\n",
    "    'classifier__min_samples_split': [2, 5, 10],  # Minimum samples required to split an internal node\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],  # Minimum number of samples at a leaf node\n",
    "    'classifier__subsample': [0.6, 0.8, 1.0],  # Subsample ratio of the training instances\n",
    "\n",
    "    # Hyperparameters for DecisionTreeClassifier\n",
    "    'classifier__criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "    'classifier__splitter': ['best', 'random'],  # Strategy used to split at each node\n",
    "    'classifier__max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'classifier__min_samples_split': [2, 5, 10],  # Minimum samples required to split an internal node\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],  # Minimum number of samples at a leaf node\n",
    "\n",
    "    # Hyperparameters for XGBClassifier\n",
    "    'classifier__n_estimators': [100, 200, 300],  # Number of boosting rounds\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],  # Learning rate shrinks the contribution of each classifier\n",
    "    'classifier__max_depth': [3, 5, 10],  # Maximum depth of the trees\n",
    "    'classifier__min_child_weight': [1, 3, 5],  # Minimum sum of instance weight needed in a child\n",
    "    'classifier__subsample': [0.6, 0.8, 1.0],  # Subsample ratio of the training instances\n",
    "    'classifier__colsample_bytree': [0.6, 0.8, 1.0],  # Subsample ratio of columns when constructing each tree\n",
    "    'classifier__gamma': [0, 0.1, 0.2],  # Minimum loss reduction required to make a further partition\n",
    "    'classifier__scale_pos_weight': [1, 10, 25],  # Controls balance of positive and negative weights for imbalanced classes\n",
    "}"
   ],
   "id": "2a9d9bae1f4e44a4",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:18:57.187555Z",
     "start_time": "2024-10-21T00:18:57.092909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your word embeddings are already prepared in X (as dense vectors) and y (target labels)\n",
    "# Example: Simulating imbalanced dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=300, n_classes=2, weights=[0.9, 0.1], random_state=42)  # Imbalanced dataset\n",
    "\n",
    "# Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with a placeholder for the classifier\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', RandomForestClassifier())  # Placeholder for the classifier\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Create a custom F1 scorer for imbalanced datasets using 'weighted' average\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# Create RandomizedSearchCV with the pipeline\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid, n_iter=10, scoring=f1_scorer, cv=5, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train_wv, y_train)\n",
    "\n",
    "# Print the best estimator and the best F1 score\n",
    "print(f\"Best estimator: {random_search.best_estimator_}\")\n",
    "print(f\"Best F1 score (cross-validated): {random_search.best_score_}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = random_search.predict(X_test)\n",
    "test_f1_score = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Test set F1 score: {test_f1_score}\")"
   ],
   "id": "6a27ba2a33f6e18f",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter learning_rate for estimator RandomForestClassifier(max_depth=30, n_estimators=50). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[162], line 31\u001B[0m\n\u001B[1;32m     28\u001B[0m random_search \u001B[38;5;241m=\u001B[39m RandomizedSearchCV(pipeline, param_distributions\u001B[38;5;241m=\u001B[39mparam_grid, n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, scoring\u001B[38;5;241m=\u001B[39mf1_scorer, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Fit the model\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m \u001B[43mrandom_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_wv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Print the best estimator and the best F1 score\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest estimator: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrandom_search\u001B[38;5;241m.\u001B[39mbest_estimator_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/transformer-test-3-8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:891\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    885\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    886\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    887\u001B[0m     )\n\u001B[1;32m    889\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 891\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    894\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    895\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/transformer-test-3-8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1766\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1764\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1765\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1766\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1767\u001B[0m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1768\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[1;32m   1769\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1770\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/transformer-test-3-8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:838\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    831\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    832\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    833\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    834\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    835\u001B[0m         )\n\u001B[1;32m    836\u001B[0m     )\n\u001B[0;32m--> 838\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    840\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    841\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    842\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    843\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    844\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    857\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    858\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    859\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    860\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/transformer-test-3-8/lib/python3.8/site-packages/joblib/parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[1;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[1;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[1;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[1;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[1;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[1;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/transformer-test-3-8/lib/python3.8/site-packages/joblib/parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/transformer-test-3-8/lib/python3.8/site-packages/sklearn/utils/fixes.py:211\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    210\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[0;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/transformer-test-3-8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:669\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    666\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m parameters\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    667\u001B[0m         cloned_parameters[k] \u001B[38;5;241m=\u001B[39m clone(v, safe\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m--> 669\u001B[0m     estimator \u001B[38;5;241m=\u001B[39m \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_params\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcloned_parameters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    671\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    673\u001B[0m X_train, y_train \u001B[38;5;241m=\u001B[39m _safe_split(estimator, X, y, train)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/transformer-test-3-8/lib/python3.8/site-packages/sklearn/pipeline.py:188\u001B[0m, in \u001B[0;36mPipeline.set_params\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_params\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    170\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Set the parameters of this estimator.\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \n\u001B[1;32m    172\u001B[0m \u001B[38;5;124;03m    Valid parameter keys can be listed with ``get_params()``. Note that\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;124;03m        Pipeline class instance.\u001B[39;00m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 188\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_params\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msteps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/transformer-test-3-8/lib/python3.8/site-packages/sklearn/utils/metaestimators.py:54\u001B[0m, in \u001B[0;36m_BaseComposition._set_params\u001B[0;34m(self, attr, **params)\u001B[0m\n\u001B[1;32m     52\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_replace_estimator(attr, name, params\u001B[38;5;241m.\u001B[39mpop(name))\n\u001B[1;32m     53\u001B[0m \u001B[38;5;66;03m# 3. Step parameters and other initialisation arguments\u001B[39;00m\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_params\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/transformer-test-3-8/lib/python3.8/site-packages/sklearn/base.py:253\u001B[0m, in \u001B[0;36mBaseEstimator.set_params\u001B[0;34m(self, **params)\u001B[0m\n\u001B[1;32m    250\u001B[0m         valid_params[key] \u001B[38;5;241m=\u001B[39m value\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, sub_params \u001B[38;5;129;01min\u001B[39;00m nested_params\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m--> 253\u001B[0m     \u001B[43mvalid_params\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_params\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msub_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/transformer-test-3-8/lib/python3.8/site-packages/sklearn/base.py:240\u001B[0m, in \u001B[0;36mBaseEstimator.set_params\u001B[0;34m(self, **params)\u001B[0m\n\u001B[1;32m    238\u001B[0m key, delim, sub_key \u001B[38;5;241m=\u001B[39m key\u001B[38;5;241m.\u001B[39mpartition(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m valid_params:\n\u001B[0;32m--> 240\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    241\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid parameter \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m for estimator \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    242\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCheck the list of available parameters \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    243\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith `estimator.get_params().keys()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (key, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    244\u001B[0m     )\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m delim:\n\u001B[1;32m    247\u001B[0m     nested_params[key][sub_key] \u001B[38;5;241m=\u001B[39m value\n",
      "\u001B[0;31mValueError\u001B[0m: Invalid parameter learning_rate for estimator RandomForestClassifier(max_depth=30, n_estimators=50). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "execution_count": 162
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
